import os  # Pour la variable d'environnement NCBI_API_KEY
import streamlit as st
import pandas as pd
import io
import ast, json
import traceback

# Importer les fonctions et constantes partagÃ©es depuis utils.py
from utils import (
    get_scopus_data, get_openalex_data, get_pubmed_data, convert_to_dataframe,
    clean_doi, HalCollImporter, merge_rows_with_sources, get_authors_from_crossref,
    check_df, enrich_w_upw_parallel, add_permissions_parallel, deduce_todo,
    normalise, normalize_name, get_initial_form
)

# Importer la gÃ©nÃ©ration ZIP / XML (hal_xml_export.py)
from hal_xml_export import generate_zip_from_xmls, extract_authors_from_openalex_json, _safe_text

# --- DÃ©finition de la liste des laboratoires (spÃ©cifique Ã  cette application) ---
labos_list_rennes = [
    {
        "collection": "CAPHI", "scopus_id": "60105490", "openalex_id": "I4387152714", "openalex_raw":"(\"Centre Atlantique de Philosophie\") OR CAPHI OR UR7463 OR (\"UR 7463\") OR (\"UR 1270\") OR UR1270  OR (\"EA 1270\") OR EA1270",
        "pubmed_query": "(CAPHI[Affiliation]) OR (\"CENTRE ATLANTIQUE DE PHILOSOPHIE\"[Affiliation]) OR (\"EA 7463\" [Affiliation]) OR (EA7463[Affiliation]) OR (UR7463[Affiliation]) OR (\"UR 7463\"[Affiliation])"
    },
    {
        "collection": "ARENES", "scopus_id": "60105601", "openalex_id": "I4387155702", "openalex_raw":"UMR6051 OR \"Centre de recherches sur l'action politique en Europe\" OR CRAPE OR ARENES",
        "pubmed_query": "(ARENES[Affiliation]) OR (\"UMR6051\"[Affiliation]) OR (UMR 6051[Affiliation] OR OR (UMR CNRS 6051[Affiliation])"
    },
        {"collection": "CREAAH", "scopus_id": "60105602", "openalex_id": "I4387153012", "openalex_raw":"UMR6566 OR \"UMR 6566\" OR \"CNRS 6566\" OR \"Centre de recherche en archÃ©ologie archÃ©osciences histoire\" OR CReAAH OR \"Archaeology Archaeoscience and History\"", "pubmed_query": ""},
    {
        "collection": "BIOSIT", "scopus_id": "", "openalex_id": "", "openalex_raw":"ImPACcell OR H2P2 OR mric OR Protim OR FAIIA OR Prism",
        "pubmed_query": "(FAIIA[affiliation]) OR (mric[affiliation]) OR (prism[affiliation]) OR (H2P2[affiliation]) OR (Protim[affiliation]) OR (ImPACcell[affiliation])"
    },
    {
        "collection": "BRM", "scopus_id": "60206583", "openalex_id": "I4387155446", "openalex_raw":"\"ARN bactÃ©riens et mÃ©decine\" OR \"Bacterial RNAs and Medicine\" OR \"ARN rÃ©gulateurs bactÃ©riens et mÃ©decine\" OR \"Bacterial regulatory RNAs and Medicine\" OR U1230 OR UMR1230 OR U835 OR \"U 1230\" OR \"U 835\" OR \"UMR_S 1230\" OR \"UMR_S1230\" OR \"Bacterial RNAs Function Structure\" OR \"Fonction structure et inactivation\"",
        "pubmed_query": "(U835[affiliation]) OR (UMR_S1230[affiliation]) OR (UMR1230[affiliation]) OR (U1230[affiliation]) OR (\"ARN rÃ©gulateurs bactÃ©riens et mÃ©decine\"[affiliation]) OR (\"Bacterial regulatory RNAs and Medicine\"[affiliation]) OR ((Tattevin[Author]) OR (Cattoir[Author]) OR (Revest[Author]) OR (Le Pabic[Author]) OR (Donnio[Author]) OR (Le Pabic[Author]) AND Rennes[affiliation])"
    },
    {
        "collection": "CIC", "scopus_id": "60105521", "openalex_id": "I4210116274", "openalex_raw":"\"CIC Rennes\" OR \"UnitÃ© dÊ¼Investigation Clinique de Rennes\" OR \"Centre dÊ¼Investigation Clinique de Rennes\" OR \"Rennes Clinical investigation\" OR CIC1414 OR CIC203 OR CIC0203 OR \"CIC 1414\" OR \"CIC 203\" OR \"CIC 0203\" OR \"CIC-INSERM 1414\"",
        "pubmed_query": "((\"INSERM 1414\"[Affiliation]) OR (INSERM-CIC-1414[Affiliation]) OR (CIC-1414[Affiliation]) OR (0203[Affiliation]) OR (1414[Affiliation]) OR (\"INSERM 0203\"[Affiliation]) OR (\"UnitÃ© dÊ¼Investigation Clinique Rennes\"[Affiliation]) OR (\"Centre dÊ¼Investigation Clinique* Rennes\"[Affiliation]) OR (\"Clinical Investigation Center Rennes\"[Affiliation]) OR (\"Rennes Clinical Investigation Center\"[Affiliation]) NOT (\"U 804\"[Affiliation]) NOT (U804[Affiliation]) NOT (CIC-IT[Affiliation]) AND (rennes[Affiliation])) NOT (Inria[Affiliation]) NOT (FORTH/ICE-HT[Affiliation])"
    },
    {
        "collection": "OSS", "scopus_id": "60138518", "openalex_id": "I4210090689", "openalex_raw":"ERL440 OR \"ERL 440\" OR COSS OR \"Oncogenesis Stress and Signaling\" OR U1242 OR \"U 1242\" OR UMR1242 OR \"UMR 1242\"",
        "pubmed_query": "((u1242[Affiliation]) OR (\"u 1242\"[Affiliation]) OR (umrs1242[Affiliation]) OR (\"umr_s 1242\"[Affiliation]) OR (\"Oncogenesis, Stress and Signaling\"[Affiliation]) OR (COSS[Affiliation]) OR (ERL440[Affiliation]) OR (\"ERL 440\"[Affiliation]) OR (ER440[Affiliation]) OR ((HÃ©lÃ¨ne BELOEIL[Author]) OR (Julien Edeline[Author]) OR (Samer Kayal[Author]) OR (Astrid Lievre[Author]) OR (Remy Pedeux[Author]) OR (Laurent Sulpice[Author]) OR (Charles Ricordel[Author]) AND (Rennes[Affiliation]))"
    },
    {
        "collection": "ECOBIO", "scopus_id": "60105587", "openalex_id": "I4210087209", "openalex_raw":"UMR6553 OR \"UMR 6553\" OR \"Ã‰cosystÃ¨mes biodiversitÃ© Ã©volution\" OR (ECOBIO AND France) OR \"Ecosystem Biodiversity Evolution\" NOT \"Laboratoire de GÃ©ographie Physique et Environnementale\"",
        "pubmed_query": "((ecobio[Affiliation]) OR (6553[Affiliation]) OR (\"Ã‰cosystÃ¨mes, biodiversitÃ©, Ã©volution\"[Affiliation]) OR (\"Ecosystems, Biodiversity, Evolution\"[Affiliation]) AND (rennes[Affiliation])) OR (paimpont[Affiliation])"
    },
    {
        "collection": "ETHOS", "scopus_id": "60105604", "openalex_id": "I4387154707", "openalex_raw":"((UMR6552 OR \"UMR 6552\" OR \"Ethologie animale et humaine\" OR \"animal and human ethology\" OR \"Ã‰thologie animale et humaineâ€”UMR 6552\" OR ETHOS) AND (France))",
        "pubmed_query": "(UMR6552[Affiliation]) OR (\"UMR 6552\"[Affiliation]) OR (\"UMR* 6552\"[Affiliation]) OR (\"Ethologie animale et humaine\"[Affiliation]) OR (\"animal and human ethology\"[Affiliation])"
    },
    {
        "collection": "FOTON", "scopus_id": "60105599", "openalex_id": "I4210138837", "openalex_raw":"UMR6082 OR \"UMR 6082\" OR \"Fonctions Optiques pour les Technologies\" OR \"Optical Functions for Information Technology\" OR ENSSAT OR (FOTON AND France) NOT \"DEOS - DÃ©partement Electronique Optronique et Signal\"",
        "pubmed_query": "(\"Fonctions Optiques pour les Technologies de lâ€™information\"[Affiliation]) OR (UMR6082[Affiliation]) OR (UMR 6082[Affiliation])"
    },
    {
        "collection": "IETR", "scopus_id": "60105585", "openalex_id": "I4210100151", "openalex_raw":"(UMR6164 OR \"UMR 6164\" OR \"Institut dâ€™Ã‰lectronique et de TÃ©lÃ©communication de Rennes\" OR \"Institut d electronique et de Telecommunication de Rennes\" OR \"Institute of Electronics and Telecommunications of Rennes\" OR IETR OR \"Institut d'Ã‰lectronique et des Technologies du numÃ©Rique\" OR \"IETRâ€“UMR\") NOT (Nantes) NOT (\"Innovative Research Unit of Epithelial Transport and Regulation\"),display_name:!Batard|Bourlier|Charge|Chousseaud|Descamps|Diouris|El Assad|El Gibari|Feuvrie|Froppier|Ginot|Guiffard|Gundel|Le Bastard|Le Nours|Li Hong|Mahe|Motta Cruz|Pasquier|Pillement|Poulain|Razban|Wang",
        "pubmed_query": "(IETR[Affiliation]) OR (Institut d'Ã‰lectronique et des Technologies du numÃ©Rique[Affiliation]) OR (UMR6164[Affiliation]) OR (UMR 6164[Affiliation]) OR (IETR Polytech[Affiliation]) OR (Institut d'Electronique et des Technologies du numÃ©Rique[Affiliation]) OR (Institut d'Ã‰lectronique et de TÃ©lÃ©communications[Affiliation])"
    },
    {
        "collection": "IGDR", "scopus_id": "60105597", "openalex_id": "I4210127029", "openalex_raw":"ERL1305 OR \"ERL 1305\" OR UMR6290 OR \"UMR 6290\" OR IGDR OR \"Institut de gÃ©nÃ©tique et dÃ©veloppement de Rennes\" OR \"Institut de genetique et developpement de Rennes\" NOT \"Instituto de GeografÃ­a y Desarrollo Regional\"",
        "pubmed_query": "(IGDR[Affiliation]) OR (6290[Affiliation]) OR (\"Institut de gÃ©nÃ©tique et dÃ©veloppement de Rennes\"[Affiliation]) OR (\"Institute of Genetics and Development of Rennes\"[Affiliation]) OR (Lise BOUSSEMART[Author]) OR (VÃ©ronique DAVID[Author]) OR (Marie DE TAYRAC[Author]) OR (Virginie DELIGNIERE-GANDEMER[Author]) OR (Virginie GANDEMER[Author]) OR (ChristÃ¨le DUBOURG[Author]) OR (Marie-Domininique GALIBERT[Author]) OR (Jean MOSSER[Author]) OR (Sylvie ODENT[Author]) NOT (Nikon[Affiliation])"
    },
    {
        "collection": "IPR", "scopus_id": "60105586", "openalex_id": "I4210109443", "openalex_raw":"UMR6251 OR \"UMR 6251\" OR \"CNRS 6251\" OR UMR-6251 OR \"Institut de physique de Rennes\" OR \"Institute of Physics of Rennes\" OR \"Rennes Institute of Physics\" OR LARMAUR OR \"Mecanique et Verres\" OR (IPR AND France) NOT (\"Institut Pierre Richet\" OR \"Intelligent Process Automation and Robotics\" OR \"Sant Joan de Deu\" OR \"Institut Polytechnique Rural de Formation et de Recherche Appliquee\" OR \"Institut Paris Region\")",
        "pubmed_query": "((IPR[Affiliation]) AND (rennes[Affiliation])) OR (\"Institut de Physique de Rennes\"[Affiliation]) OR (UMR6251[Affiliation]) OR (\"UMR 6251\"[Affiliation]) NOT (\"Institut Pierre Richet\"[Affiliation]) NOT (\"Intelligent Process Automation and Robotics\"[Affiliation]) NOT (\"Sant Joan de DÃ©u\"[Affiliation])"
    },
    {
        "collection": "IRSET", "scopus_id": "60105594", "openalex_id": "I4210108239", "openalex_raw":"UMR1085 OR U1085 OR \"U 1085\" OR IRSET OR \"Research Institute for Environmental and Occupational Health\" OR \"Institut de Recherche en SantÃ© Environnement et Travail\" OR \"Institut de Recherche en Sante Environnement et Travail\" OR \"IRSET-INSERM-1085\" OR \"Irset-UMR_S 1085\" OR \"UMR_S 1085\" OR \"Institute for Research in Health Environment and Work\" OR \"UMRS 1085\"  OR \"UMR 1085\" NOT (ISORG OR \"Julia Ester Gonzales Delgado de Loja\" OR \"Department of Speech Language and Hearing Sciences\"),institutions.id:!I157943965|I43526919|I4210159825| I101202996,display_name:!Kristensen David MÃ¸bjerg|!Kristensen David M,author.id:!A5042113315|A5034669762",
        "pubmed_query": "(irset[Affiliation]) OR (U1085[Affiliation]) OR (UMR1085[Affiliation]) OR (\"UMR-S 1085\"[Affiliation]) OR (\"UMR_S 1085\"[Affiliation]) OR (\"Institut de recherche en santÃ©, environnement et travail\"[Affiliation]) OR (\"Research Institute for Environmental and Occupational Health\"[Affiliation]) OR (\"Institute for Research in Health Environment and Work\"[Affiliation]) OR (Marc-Antoine BELAUD-ROTUREAU[Author]) OR (CÃ©lia Ravel[Author]) OR (Nathalie RIOUX-LECLERCQ[Author]) OR (CÃ©cile VIGNEAU[Author]) OR (FrÃ©deric DUGAY[Author]) OR (Sylvie JAILLARD[Author]) OR (Romain MATHIEU[Author]) OR (SolÃ¨ne-Florence KAMMERER-JACQUET[Author]) OR (Jonathan CHEMOUNY[Author]) NOT (IRSET-Center[Affiliation]) NOT (Kristensen[Author]"
    },
    {
        "collection": "ISCR", "scopus_id": "60072944", "openalex_id": "I4210090783", "openalex_raw":"UMR6226 OR \"UMR 6226\" OR \"ISCR â€“ UMR 6226\" OR ISCR OR \"ISCR-UMR\" OR \"ISCR-UMR6226\" OR \"Institut des sciences chimiques de Rennes\" OR \"Sciences chimiques de Rennes\" OR MACSE OR \"Chemical Institute of Rennes\" OR \"Glasses and Ceramics\" OR PNSCM OR \"Rennes National Higher School of Chemistry\" OR \"Laboratory of Glasses and Ceramics\" OR \"Rennes Institute of Chemical Science\" OR \"Rennes Institute for Chemical Science\" OR \"Rennes Institute for Chemical Sciences\" OR \"Ã‰cole nationale supÃ©rieure de chimie de Rennes\" OR ENSCR OR \"Institute of Chemical Sciences of Rennes\"",
        "pubmed_query": "((\"institut des sciences chimiques de rennes\"[Affiliation]) OR (6226[Affiliation]) OR (ISCR[Affiliation]) OR (ISCR-UMR[Affiliation]) OR (\"National Higher School of Chemistry\"[Affiliation]) OR (MACSE[Affiliation]) OR (CORINT[Affiliation]) OR (\"Glasses and Ceramics\"[Affiliation]) OR (\"Institute of Chemical Science\"[Affiliation]) OR (\"Institute for Chemical Science\"[Affiliation]) OR (\"Ecole nationale supÃ©rieure de chimie de Rennes\"[Affiliation]) OR (ENSCR[Affiliation]) AND (rennes[Affiliation]))"
    },
    {
        "collection": "LGCGM", "scopus_id": "60105557", "openalex_id": "I4387155956", "openalex_raw":"(\"Laboratory of Civil Engineering and Mechanical Engineering\" OR UR3913 OR \"Laboratoire de gÃ©nie civil et gÃ©nie mÃ©canique\" OR \"Laboratoire de gÃ©nie civil et gÃ©nie mÃ©canique\" OR LGCGM OR \"UR 3913\" OR EA3913 OR \"EA 3913\" OR \"Laboratoire de gÃ©nie civil et de gÃ©nie mÃ©canique\" OR \"Structural Engineering Research Group Lab\") AND (France)",
        "pubmed_query": "(LGCGM[Affiliation]) OR (UR 3913[Affiliation]) OR (UR3913[Affiliation]) OR (EA 3913[Affiliation]) OR (EA3913[Affiliation]) OR (\"Laboratoire de gÃ©nie civil et gÃ©nie mÃ©canique\"[Affiliation] OR ((Quang Huy Nguyen[Author]) OR (MaÃ«l Couchaux[Author]) OR (Fabrice Bernard[Author]) OR (Paul Byrne[Author]) OR (Amina Meslem[Author]) OR (Florence Collet[Author]) OR (Mohammed Hjiaj[Author]) OR (Piseth Heng[Author]) OR (Hugues Somja[Author]) OR (Siham Kamali-Bernard[Author]) OR (Balaji Raghavan[Author]) AND (rennes[Affiliation]))"
    },
    {
        "collection": "LTSI", "scopus_id": "60105589", "openalex_id": "I4210105651", "openalex_raw":"\"UMR-1099\" OR UMR1099 OR U1099 OR \"U 1099\" OR \"UMR 1099\" OR \"UMR_S 1099\" OR LTSI OR CRIBS OR \"CIC-IT 804\" OR \"CIC-IT804\" OR \"CIC-IT Rennes\" OR \"Laboratoire traitement du signal et de l'image\" OR \"Laboratoire traitement du signal et de l image\" OR \"Signal and Image Processing Laboratory\" OR \"Centre de Recherche en Information BiomÃ©dicale Sino-FranÃ§ais\" OR \"Centre de Recherche en Information Biomedicale Sino-Francais\" OR (medicis AND Rennes) NOT (BiSIPL OR SIPL OR \"Remote Sensing Signal and Image Processing Laboratory\" OR \"Biomedical Signal and Image Processing Laboratory\" OR \"Industrial Technologies and Services Laboratory\" OR \"Laboratoire de Recherches Technologies et Services Industriels\" OR \"KSIP lab\" OR \"Center for Research for Infant Birth and Survival\")",
        "pubmed_query": "(LTSI[Affiliation]) OR (U1099[Affiliation]) OR (UMR1099[Affiliation]) OR (UMR* 1099[Affiliation]) OR (CRIBS[Affiliation]) OR (Centre de recherche en information biomÃ©dicale sino-franÃ§ais[Affiliation]) OR (CIC-IT[Affiliation]) OR (U* 804[Affiliation]) OR (medicis[Affiliation]) OR (Signal and Image Processing Laboratory[Affiliation] OR (\"Laboratoire traitement du signal et de l'image\"[Affiliation]) OR (\"Centre de Recherche en Information BiomÃ©dicale Sino-FranÃ§ais\"[Affiliation])"
    },
    {
        "collection": "M2S", "scopus_id": "60105531", "openalex_id": "I4210160484", "openalex_raw":"\"UR 7470\" OR UR7470 OR UR1274 OR \"UR 1274\" OR \"EA 7470\" OR EA7470 OR EA1274 OR \"EA 1274\" OR M2S OR \"Laboratoire mouvement sport et santÃ©\" OR (Movement Sport Health AND Rennes) ",
        "pubmed_query": "(UR* 7470[Affiliation]) OR (UR7470[Affiliation]) OR (UR* 1274[Affiliation]) OR (EA* 7470[Affiliation]) OR (EA7470[Affiliation]) OR (EA* 1274[Affiliation]) OR (EA1274[Affiliation]) OR (\"Laboratoire mouvement, sport et santÃ©\"[Affiliation]) OR (\"Movement, Sport, Health\"[Affiliation]) OR (M2S[Affiliation])"
    },
    {
        "collection": "MOBIDIC", "scopus_id": "60105591", "openalex_id": "I4387154398", "openalex_raw":"mobidic OR u1236 OR micmac OR \"Microenvironment and B-cells\" OR UMR1236 OR u917 OR \"UMR_ S 1236\"",
        "pubmed_query": "(MOBIDIC[Affiliation]) OR (Microenvironment and B-cells: Immunopathology, Cell Differentiation, and Cancer[Affiliation]) OR (Microenvironment and B-cells and Cancer[Affiliation]) OR (micmac[Affiliation]) OR (Microenvironment, Cell Differentiation, Immunology and Cancer[Affiliation]) OR (UMR_S 1236[Affiliation]) OR (U1236[Affiliation]) OR (U* 1236[Affiliation]) OR (UMR_S1236[Affiliation]) OR (u917[Affiliation]) OR (U 917[Affiliation]) OR (UMR_S917[Affiliation]) OR (UMR_S 917[Affiliation]) OR ((Olivier Decaux[Author] OR Roch Houot[Author]) AND Rennes[Affiliation])) NOT (Educell Ltd[Affiliation]) NOT (MicMac Road[Affiliation]) NOT (Montpellier BioInformatics for Clinical Diagnosis[Affiliation]))"
    },
    {
        "collection": "NUMECAN", "scopus_id": "60112105", "openalex_id": "I4387156410", "openalex_raw":"UMR1317 OR (NUMECAN AND Rennes) OR (NUMECAN AND \"Saint-Gilles\") OR U1317 OR \"U 1317\" OR \"U-1317\" OR UMR1241 OR \"U 1241\" OR \"U-1241\" OR EA1254 OR \"EA 1254\" OR U991 OR \"U 991\" OR (\"Nutrition MÃ©tabolismes et Cancer\" AND Rennes)",
        "pubmed_query": "(UMR991[affiliation]) OR (UMR 991[affiliation]) OR (U991[affiliation]) OR (U* 991[affiliation]) OR (foie, mÃ©tabolismes et cancer[affiliation]) OR (foie, metabolismes et cancer[affiliation]) OR (liver, metabolisms and cancer[affiliation]) OR (EA 1254[affiliation]) OR (EA1254[affiliation]) OR (microbiologie: risques infectieux[affiliation]) OR (U1317[Affiliation]) OR (U 1317[Affiliation]) OR (U-1317[Affiliation]) OR (UMR_S 1317[Affiliation]) OR (UMR 1317[Affiliation]) OR (U1241[Affiliation]) OR (U 1241[Affiliation]) OR (U-1241[Affiliation]) OR (UMR_S 1241[Affiliation]) OR (UMR 1241[Affiliation]) OR (UMR 1341[Affiliation]) OR (UMR INRA 1341[Affiliation]) OR (numecan[Affiliation]) OR (nutrition, mÃ©tabolismes et cancer[Affiliation]) OR (nutrition, metabolismes et cancer[Affiliation]) OR (nutrition, metabolisms and cancer[Affiliation]) OR ((ARNAUD Alexis OR BELLANGER Amandine OR BUFFET-BATAILLON Sylvie OR MOIRAND Romain OR THIBAULT Ronan OR ARTRU Florent OR BENDAVID Claude OR BOUGUEN Guillaume OR CABILLIC Florian OR GICQUEL Thomas OR LE DARE Brendan OR LEBOUVIER Thomas OR MOREL Isabelle OR NESSELER Nicolas  OR PELLETIER Romain OR PEYRONNET Benoit OR RAYAR Michel OR  SIPROUDHIS Laurent OR GUGGENBUHL Pascal OR  BARDOU-JACQUET Edouard OR BONNET Fabrice OR DESCLOS-THEVENIAU Marie OR GARIN Etienne OR HAMDI-ROZE Houda OR LAINE Fabrice OR MEURIC Vincent OR RANGE HÃ©lÃ¨ne OR ROBIN FranÃ§ois OR ROPARS Mickael OR ROPERT Martine OR TURLIN Bruno) AND (Rennes[Affiliation]))"
    },
    {
        "collection": "SCANMAT", "scopus_id": "60138457", "openalex_id": "I4387156459", "openalex_raw":"SCANMAT OR UMS2001 OR \"UMS 2001\" OR \"SynthÃ¨se CaractÃ©risations Analyses de la MATiÃ¨re\" OR UAR2025 OR \"UAR 2025\"",
        "pubmed_query": "(SCANMAT[affiliation]) OR (UMS2001[affiliation])"
    },
    {
        "collection": "CREM", "scopus_id": "60105603", "openalex_id": "I4210088544", "openalex_raw":"(UMR6211 OR \"UMR 6211\" OR CREM OR \"Centre de recherche en Ã©conomie et management\" OR \"Centre de recherche en economie et management\" OR \"Center for Research in Economics and Management\" OR \"IGR-IAE\" OR IGR OR \"Institut de gestion de Rennes\") AND (Rennes OR Caen) NOT Villejuif NOT \"Centre de Recherche sur les MÃ©diations\"",
        "pubmed_query": ""
    },
    {
        "collection": "VIPS2", "scopus_id": "60105580", "openalex_id": "I4387155754", "openalex_raw":"\"Valeurs Innovations Politiques Socialisations Sports\" OR VIPS2 OR VIPS OR \"UR 4636\" OR UR4636",
        "pubmed_query": "(VIPS2[Affiliation]) OR (Valeurs, Innovations, Politiques, Socialisations et Sports[Affiliation]) OR (UR 4636[Affiliation]) OR (UR4636[Affiliation])"
    },
    {
        "collection": "GR", "scopus_id": "60070475", "openalex_id": "i4210096833", "openalex_raw":"\"GÃ©osciences Rennes\" OR \"Geosciences Rennes\" OR UMR6118 OR VIPS OR \"UMR 6118\" OR \"CNRS 6118\" OR UMR-6118",
        "pubmed_query": "(Geosciences Rennes[Affiliation]) OR (CNRS 6118[Affiliation]) OR (UMR 6118[Affiliation]) OR (UMR-6118[Affiliation]) OR (UMR6118[Affiliation])"
    },
    {
        "collection": "IRISA", "scopus_id": "60027031", "openalex_id": "i2802519937", "openalex_raw":"\"Institut de Recherche en Informatique et SystÃ¨mes AlÃ©atoires\" OR \"Institut de Recherche en Informatique et Systemes Aleatoires\" OR UMR6074 OR UMR-6074 OR \"UMR 6074\" OR \"CNRS 6074\" OR \" Institute for Research in IT and Random Systems\" OR IRISA",
        "pubmed_query": "(Institut de Recherche en Informatique et SystÃ¨mes AlÃ©atoires[Affiliation]) OR (Institute for Research in IT and Random Systems[Affiliation]) OR (IRISA[Affiliation]) OR (UMR6074[Affiliation]) OR (UMR 6074[Affiliation]) OR (UMR-6074[Affiliation]) OR (CNRS 6074[Affiliation])"
    },
    {
        "collection": "CDA-PR", "scopus_id": "60105488", "openalex_id": "i4387152641", "openalex_raw":"\"Centre de droit des affaires\" OR \"UR 3195\" OR UR 3195 OR UR-3195 OR \"EA 3195\" OR \"EA-3195\" OR EA3195",
        "pubmed_query": "(Centre de droit des affaires[Affiliation]) OR (UR 3195[Affiliation]) OR (UR3195[Affiliation]) OR (EA 3195[Affiliation]) OR (EA3195[Affiliation])"
    },
    {
        "collection": "IGEPP", "scopus_id": "60105596", "openalex_id": "i4210141755", "openalex_raw":"\"Institut de GÃ©nÃ©tique Environnement et Protection des Plantes\" OR \"Institut de Genetique Environnement et Protection des Plantes\" OR IGEPP OR UMR1349 OR \"UMR 1349\" OR \"INRAE 1349\" OR UMR-1349",
        "pubmed_query": "(IGEPP[Affiliation]) OR (Institut de Genetique Environnement et Protection des Plantes[Affiliation]) OR (UMR 1349[Affiliation]) OR (UMR1349[Affiliation]) OR (UMR-1349[Affiliation])"
    },
    {
        "collection": "IDPSP", "scopus_id": "60105593", "openalex_id": "i4387154572", "openalex_raw":"\"Institut du droit public et de la science politique\" OR IDPSP OR UR4640 OR \"UR 4640\" OR \"EA 4640\" OR UR-4640 OR EA4640",
        "pubmed_query": "(IDPSP[Affiliation]) OR (Institut du droit public et de la science politique[Affiliation]) OR (UR 4640[Affiliation]) OR (UR4640[Affiliation]) OR (UR-4640[Affiliation])"
    },
    {
        "collection": "IODE", "scopus_id": "60105639", "openalex_id": "i4210128017", "openalex_raw":"\"Institut de l'Ouest : Droit et Europe\" OR \"Institut de l Ouest Droit et Europe\" OR (IODE AND Rennes) OR UMR6262 OR \"Western Institute of Law and Europe\" OR \"UMR 6262\" OR \"CNRS 6262\" OR UMR-6262",
        "pubmed_query": "(Institut de l'Ouest : Droit et Europe[Affiliation]) OR (Western Institute of Law and Europe[Affiliation]) OR (UMR6262[Affiliation]) OR (UMR 6262[Affiliation]) OR (UMR-6262[Affiliation]) OR (UMR-6262[Affiliation] AND Rennes)"
    },
    {
        "collection": "EMPENN-R", "scopus_id": "60206629", "openalex_id": "i4387152452", "openalex_raw":"Empenn OR \"U 1228\" OR (VISAGES AND Rennes) OR UMRS1228 OR \"UMRS 1228\" OR \"UMR_S 1228\" OR \"UMR 1228\" OR UMR1228 OR UMR-1228",
        "pubmed_query": "(EMPENN[Affiliation]) OR (VISAGES[Affiliation] AND Rennes) OR (UMRS1228[Affiliation]) OR (UMRS 1228[Affiliation]) OR (UMR_S 1228[Affiliation]) OR (UMR1228[Affiliation]) OR (UMR 1228[Affiliation]) OR (UMR-1228[Affiliation])"
    },
    {
        "collection": "IRMAR", "scopus_id": "60105640", "openalex_id": "i4210161663", "openalex_raw":"IRMAR OR \"Institut de recherche mathÃ©matique de Rennes\" OR UMR6625 OR \"Institut de recherche mathematique de Rennes\" OR \"Mathematics Research Institute of Rennes\" OR \"UMR 6625\" OR UMR-6625 OR \"CNRS 6625\"",
        "pubmed_query": "(IRMAR[Affiliation]) OR (Institut de recherche mathÃ©matique de Rennes[Affiliation] AND Rennes) OR (Mathematics Research Institute of Rennes[Affiliation]) OR (UMR 6625[Affiliation]) OR (UMR6625[Affiliation]) OR (UMR-6625[Affiliation]) OR (CNRS 6625[Affiliation])"
    },
]
labos_df_rennes_global = pd.DataFrame(labos_list_rennes)


# Fonction pour ajouter le menu de navigation (spÃ©cifique Ã  cette app)
def add_sidebar_menu():
    st.sidebar.header("Ã€ Propos")
    st.sidebar.info(
    """
    **c2LabHAL - Version UniversitÃ© de Rennes** :
    Cette version est prÃ©configurÃ©e pour les laboratoires de l'UniversitÃ© de Rennes.
    SÃ©lectionnez un laboratoire dans la liste pour lancer la comparaison de ses publications
    (Scopus, OpenAlex, PubMed) avec sa collection HAL. c2LabHAL est une application crÃ©Ã©e par Guillaume Godet (Nantes Univ)
    """
)
    st.sidebar.markdown("---")

    st.sidebar.header("Autres applications c2LabHAL")
    st.sidebar.markdown("ðŸ“– [c2LabHAL - Application Principale](https://c2labhal.streamlit.app/)")
    st.sidebar.markdown("ðŸ“„ [c2LabHAL version CSV](https://c2labhal-csv.streamlit.app/)")


    st.sidebar.markdown("---")
    
    st.sidebar.markdown("PrÃ©sentation du projet :")
    st.sidebar.markdown("[ðŸ“Š Voir les diapositives](https://slides.com/guillaumegodet/deck-d5bc03#/2)")
    st.sidebar.markdown("Code source :")
    st.sidebar.markdown("[ðŸ™ Voir sur GitHub](https://github.com/GuillaumeGodet/c2labhal)")


def main():
    st.set_page_config(page_title="c2LabHAL - Rennes", layout="wide")

    # Initialisation des clÃ©s session (protÃ¨ge contre les reruns)
    st.session_state.setdefault('zip_buffer', None)
    st.session_state.setdefault('publications_list', [])
    st.session_state.setdefault('last_result_df', None)       # contient la table rÃ©sultat sÃ©rialisÃ©e (list of dicts)
    st.session_state.setdefault('last_collection', None)      # collection traitÃ©e (nom)
    st.session_state.setdefault('zip_buffer', None)           # bytes du zip gÃ©nÃ©rÃ©

    add_sidebar_menu() 

    st.title("ðŸ¥Ž c2LabHAL - Version UniversitÃ© de Rennes")
    st.subheader("Comparez les publications dâ€™un laboratoire de l'UniversitÃ© de Rennes avec sa collection HAL")

    labo_choisi_nom_rennes = st.selectbox(
        "Choisissez une collection HAL de laboratoire (UniversitÃ© de Rennes) :", 
        sorted(labos_df_rennes_global['collection'].unique())
    )

    labo_selectionne_details_rennes = labos_df_rennes_global[labos_df_rennes_global['collection'] == labo_choisi_nom_rennes].iloc[0]
    collection_a_chercher_rennes = labo_selectionne_details_rennes['collection']
    scopus_lab_id_rennes = labo_selectionne_details_rennes.get('scopus_id', '') 
    openalex_institution_id_rennes = labo_selectionne_details_rennes.get('openalex_id', '')
    openalex_institution_raw_rennes = labo_selectionne_details_rennes.get('openalex_raw', '') # ajout Laurent
    pubmed_query_labo_rennes = labo_selectionne_details_rennes.get('pubmed_query', '')

    scopus_api_key_secret_rennes = st.secrets.get("SCOPUS_API_KEY")
    pubmed_api_key_secret_rennes = st.secrets.get("PUBMED_API_KEY")

    col1_dates_rennes, col2_dates_rennes = st.columns(2)
    with col1_dates_rennes:
        start_year_rennes = st.number_input("AnnÃ©e de dÃ©but", min_value=1900, max_value=2100, value=2020, key="rennes_start_year")
    with col2_dates_rennes:
        end_year_rennes = st.number_input("AnnÃ©e de fin", min_value=1900, max_value=2100, value=pd.Timestamp.now().year, key="rennes_end_year")

    with st.expander("ðŸ”§ Options avancÃ©es pour les auteurs"):
        fetch_authors_rennes = st.checkbox("ðŸ§‘â€ðŸ”¬ RÃ©cupÃ©rer les auteurs via Crossref (peut ralentir)", value=False, key="rennes_fetch_authors_cb")
        compare_authors_rennes = False
        uploaded_authors_file_rennes = None
        if fetch_authors_rennes:
            compare_authors_rennes = st.checkbox("ðŸ” Comparer les auteurs avec une liste de chercheurs", value=False, key="rennes_compare_authors_cb")
            if compare_authors_rennes:
                uploaded_authors_file_rennes = st.file_uploader(
                    "ðŸ“¤ TÃ©lÃ©versez un fichier CSV de chercheurs (colonnes: 'collection', 'prÃ©nom nom')", 
                    type=["csv"], 
                    key="rennes_upload_authors_fu",
                    help="Le fichier CSV doit avoir une colonne 'collection' (code de la collection HAL) et une colonne avec les noms des chercheurs."
                )
    
    progress_bar_rennes = st.progress(0)
    progress_text_area_rennes = st.empty() # Correction: Suffixe _rennes ajoutÃ©

    if st.button(f"ðŸš€ Lancer la recherche pour {collection_a_chercher_rennes}"):
        if pubmed_api_key_secret_rennes and pubmed_query_labo_rennes:
            os.environ['NCBI_API_KEY'] = pubmed_api_key_secret_rennes

        scopus_df_rennes = pd.DataFrame()
        openalex_df_rennes = pd.DataFrame()
        pubmed_df_rennes = pd.DataFrame()

        # --- Ã‰tape 1 : RÃ©cupÃ©ration OpenAlex (par id institution) ---
        if openalex_institution_id_rennes:
            with st.spinner(f"RÃ©cupÃ©ration OpenAlex pour {collection_a_chercher_rennes}..."):
                progress_text_area_rennes.info("Ã‰tape 1/9 : RÃ©cupÃ©ration des donnÃ©es OpenAlex...")
                progress_bar_rennes.progress(5)
                openalex_query_complet_rennes = f"authorships.institutions.id:{openalex_institution_id_rennes},publication_year:{start_year_rennes}-{end_year_rennes}"
                openalex_data_rennes = get_openalex_data(openalex_query_complet_rennes, max_items=5000)
                if openalex_data_rennes:
                    openalex_df_rennes = convert_to_dataframe(openalex_data_rennes, 'openalex')
                    openalex_df_rennes['Source title'] = openalex_df_rennes.apply(
                        lambda row: row.get('primary_location', {}).get('source', {}).get('display_name') if isinstance(row.get('primary_location'), dict) and row['primary_location'].get('source') else None, axis=1
                    )
                    openalex_df_rennes['Date'] = openalex_df_rennes.get('publication_date', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    openalex_df_rennes['doi'] = openalex_df_rennes.get('doi', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    openalex_df_rennes['id'] = openalex_df_rennes.get('id', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    openalex_df_rennes['Title'] = openalex_df_rennes.get('title', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    cols_to_keep_rennes = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']
                    openalex_df_rennes = openalex_df_rennes[[col for col in cols_to_keep_rennes if col in openalex_df_rennes.columns]]
                    if 'doi' in openalex_df_rennes.columns:
                        openalex_df_rennes['doi'] = openalex_df_rennes['doi'].apply(clean_doi)
                st.success(f"{len(openalex_df_rennes)} publications OpenAlex trouvÃ©es pour {collection_a_chercher_rennes}.")
        progress_bar_rennes.progress(10)

        # --- Ã‰tape 1b : RÃ©cupÃ©ration OpenAlex (raw affiliation strings) ---
        if openalex_institution_raw_rennes:
            with st.spinner(f"RÃ©cupÃ©ration OpenAlex (raw) pour {collection_a_chercher_rennes}..."):
                progress_text_area_rennes.info("Ã‰tape 1/9 : RÃ©cupÃ©ration des donnÃ©es OpenAlex (raw)...")
                progress_bar_rennes.progress(12)
                openalex_query_complet_rennes = f"raw_affiliation_strings.search:{openalex_institution_raw_rennes},publication_year:{start_year_rennes}-{end_year_rennes}"
                openalex_data_rennes = get_openalex_data(openalex_query_complet_rennes, max_items=5000)

                if openalex_data_rennes:
                    openalex_df_rennes = convert_to_dataframe(openalex_data_rennes, 'openalex')
                    openalex_df_rennes['Source title'] = openalex_df_rennes.apply(
                        lambda row: row.get('primary_location', {}).get('source', {}).get('display_name')
                        if isinstance(row.get('primary_location'), dict) and row['primary_location'].get('source')
                        else None,
                        axis=1
                    )
                    openalex_df_rennes['Date'] = openalex_df_rennes.get('publication_date', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    openalex_df_rennes['doi'] = openalex_df_rennes.get('doi', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    openalex_df_rennes['id'] = openalex_df_rennes.get('id', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    openalex_df_rennes['Title'] = openalex_df_rennes.get('title', pd.Series(index=openalex_df_rennes.index, dtype='object'))
                    cols_to_keep_rennes = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']
                    openalex_df_rennes = openalex_df_rennes[[col for col in cols_to_keep_rennes if col in openalex_df_rennes.columns]]

                    if 'doi' in openalex_df_rennes.columns:
                        openalex_df_rennes['doi'] = openalex_df_rennes['doi'].apply(clean_doi)

                    # ðŸ§© ---- Bloc dâ€™enrichissement Ã  insÃ©rer ici ----
                    def enrich_with_openalex_authors(openalex_results):
                        publications = []
                        for pub in openalex_results:
                            try:
                                authors_data = extract_authors_from_openalex_json(pub)
                            except Exception as e:
                                st.warning(f"Erreur dans extract_authors_from_openalex_json pour {pub.get('id', 'inconnu')}: {e}")
                                authors_data = []

                            st.write(f"OpenAlex: '{pub.get('title', '')[:80]}' â†’ {len(authors_data)} auteurs extraits")

                            institutions = []
                            for a in authors_data:
                                for aff in a.get("raw_affiliations", []):
                                    institutions.append({
                                        "display_name": aff,
                                        "type": "institution"
                                    })
                            unique_institutions = [dict(t) for t in {tuple(d.items()) for d in institutions}]

                            publications.append({
                                "Title": pub.get("title"),
                                "doi": pub.get("doi"),
                                "Source title": pub.get("primary_location", {}).get("source", {}).get("display_name"),
                                "Date": pub.get("publication_date"),
                                "authors": authors_data,
                                "institutions": unique_institutions,
                                "Data source": "openalex"
                            })
                        return publications

                    # Application de la fonction dâ€™enrichissement
                    enriched_publications_rennes = enrich_with_openalex_authors(openalex_data_rennes)
                    st.session_state['openalex_publications_raw'] = enriched_publications_rennes
                    st.write(f"âœ… DonnÃ©es OpenAlex enrichies et stockÃ©es ({len(enriched_publications_rennes)} publications)")

                    st.write("ðŸ” VÃ©rification enrich_with_openalex_authors()")
                    st.json(enriched_publications_rennes[0])

                    openalex_df_rennes = pd.DataFrame(enriched_publications_rennes)
                    st.write("ðŸ§© DonnÃ©es OpenAlex enrichies :", openalex_df_rennes.head(2))
                    # ðŸ§© ---- Fin du bloc dâ€™enrichissement ----

                    # âœ… Et câ€™est ici que tu gardes ta ligne dâ€™origine :
                    st.success(f"{len(openalex_df_rennes)} publications OpenAlex trouvÃ©es pour {collection_a_chercher_rennes}.")

        progress_bar_rennes.progress(15)

        # --- Ã‰tape 2 : RÃ©cupÃ©ration PubMed ---
        if pubmed_query_labo_rennes: 
            with st.spinner(f"RÃ©cupÃ©ration PubMed pour {collection_a_chercher_rennes}..."):
                progress_text_area_rennes.info("Ã‰tape 2/9 : RÃ©cupÃ©ration des donnÃ©es PubMed...")
                progress_bar_rennes.progress(20)
                pubmed_full_query_rennes = f"({pubmed_query_labo_rennes}) AND ({start_year_rennes}/01/01[Date - Publication] : {end_year_rennes}/12/31[Date - Publication])"
                pubmed_data_rennes = get_pubmed_data(pubmed_full_query_rennes, max_items=5000)
                if pubmed_data_rennes:
                    pubmed_df_rennes = pd.DataFrame(pubmed_data_rennes)
                st.success(f"{len(pubmed_df_rennes)} publications PubMed trouvÃ©es pour {collection_a_chercher_rennes}.")
        else:
            st.info(f"Aucune requÃªte PubMed configurÃ©e pour {collection_a_chercher_rennes}.")
        progress_bar_rennes.progress(20)

        # --- Ã‰tape 3 : RÃ©cupÃ©ration Scopus ---
        if scopus_lab_id_rennes and scopus_api_key_secret_rennes:
            with st.spinner(f"RÃ©cupÃ©ration Scopus pour {collection_a_chercher_rennes}..."):
                progress_text_area_rennes.info("Ã‰tape 3/9 : RÃ©cupÃ©ration des donnÃ©es Scopus...")
                progress_bar_rennes.progress(25)
                scopus_query_complet_rennes = f"AF-ID({scopus_lab_id_rennes}) AND PUBYEAR > {start_year_rennes - 1} AND PUBYEAR < {end_year_rennes + 1}"
                scopus_data_rennes = get_scopus_data(scopus_api_key_secret_rennes, scopus_query_complet_rennes, max_items=5000)
                if scopus_data_rennes:
                    scopus_df_raw_rennes = convert_to_dataframe(scopus_data_rennes, 'scopus')
                    required_scopus_cols_rennes = {'dc:title', 'prism:doi', 'dc:identifier', 'prism:publicationName', 'prism:coverDate'}
                    if required_scopus_cols_rennes.issubset(scopus_df_raw_rennes.columns):
                        scopus_df_rennes = scopus_df_raw_rennes[['Data source', 'dc:title', 'prism:doi', 'dc:identifier', 'prism:publicationName', 'prism:coverDate']].copy()
                        scopus_df_rennes.columns = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']
                        if 'doi' in scopus_df_rennes.columns:
                            scopus_df_rennes['doi'] = scopus_df_rennes['doi'].apply(clean_doi)
                    else:
                        st.warning(f"DonnÃ©es Scopus incomplÃ¨tes pour {collection_a_chercher_rennes}. Scopus sera ignorÃ©.")
                        scopus_df_rennes = pd.DataFrame()
                st.success(f"{len(scopus_df_rennes)} publications Scopus trouvÃ©es pour {collection_a_chercher_rennes}.")
        elif scopus_lab_id_rennes and not scopus_api_key_secret_rennes:
            st.warning(f"L'ID Scopus est fourni pour {collection_a_chercher_rennes} mais la clÃ© API Scopus n'est pas configurÃ©e. Scopus sera ignorÃ©.")
        progress_bar_rennes.progress(30)

        # --- Ã‰tape 4 : Combinaison des donnÃ©es ---
        progress_text_area_rennes.info("Ã‰tape 4/9 : Combinaison des donnÃ©es sources...")
        combined_df_rennes = pd.concat([scopus_df_rennes, openalex_df_rennes, pubmed_df_rennes], ignore_index=True)

        if combined_df_rennes.empty:
            st.error(f"Aucune publication rÃ©cupÃ©rÃ©e pour {collection_a_chercher_rennes}. VÃ©rifiez la configuration du laboratoire.")
            st.stop()
        
        if 'doi' not in combined_df_rennes.columns:
            combined_df_rennes['doi'] = pd.NA
        combined_df_rennes['doi'] = combined_df_rennes['doi'].astype(str).str.lower().str.strip().replace(['nan', 'none', 'NaN', ''], pd.NA, regex=False)


        # --- Ã‰tape 5 : Fusion des lignes en double ---
        progress_text_area_rennes.info("Ã‰tape 5/9 : Fusion des doublons...")
        progress_bar_rennes.progress(40)
        
        with_doi_df_rennes = combined_df_rennes[combined_df_rennes['doi'].notna()].copy()
        without_doi_df_rennes = combined_df_rennes[combined_df_rennes['doi'].isna()].copy()
        
        
        merged_data_doi_rennes = pd.DataFrame()
        if not with_doi_df_rennes.empty:
            merged_data_doi_rennes = with_doi_df_rennes.groupby('doi', as_index=False).apply(merge_rows_with_sources)
            if 'doi' not in merged_data_doi_rennes.columns and merged_data_doi_rennes.index.name == 'doi':
                merged_data_doi_rennes.reset_index(inplace=True)
            if isinstance(merged_data_doi_rennes.columns, pd.MultiIndex):
                 merged_data_doi_rennes.columns = merged_data_doi_rennes.columns.droplevel(0)
        
       
        merged_data_no_doi_rennes = pd.DataFrame()
        if not without_doi_df_rennes.empty:
            merged_data_no_doi_rennes = without_doi_df_rennes.copy() 
        
       
        final_merged_data_rennes = pd.concat([merged_data_doi_rennes, merged_data_no_doi_rennes], ignore_index=True)

        if final_merged_data_rennes.empty:
            st.error(f"Aucune donnÃ©e aprÃ¨s fusion pour {collection_a_chercher_rennes}.")
            st.stop()
        st.success(f"{len(final_merged_data_rennes)} publications uniques aprÃ¨s fusion pour {collection_a_chercher_rennes}.")
        progress_bar_rennes.progress(50)

        # --- Ã‰tape 6 : Comparaison HAL ---
        coll_df_hal_rennes = pd.DataFrame()
        with st.spinner(f"Importation de la collection HAL '{collection_a_chercher_rennes}'..."):
            progress_text_area_rennes.info(f"Ã‰tape 6a/9 : Importation de la collection HAL '{collection_a_chercher_rennes}'...")
            coll_importer_rennes_obj = HalCollImporter(collection_a_chercher_rennes, start_year_rennes, end_year_rennes)
            coll_df_hal_rennes = coll_importer_rennes_obj.import_data()
            if coll_df_hal_rennes.empty:
                st.warning(f"Collection HAL '{collection_a_chercher_rennes}' vide ou non chargÃ©e.")
            else:
                st.success(f"{len(coll_df_hal_rennes)} notices HAL pour {collection_a_chercher_rennes}.")
        
        progress_text_area_rennes.info("Ã‰tape 6b/9 : Comparaison avec les donnÃ©es HAL...")
        result_df_rennes = check_df(final_merged_data_rennes.copy(), coll_df_hal_rennes, progress_bar_st=progress_bar_rennes, progress_text_st=progress_text_area_rennes)
        st.success(f"Comparaison HAL pour {collection_a_chercher_rennes} terminÃ©e.")

        # --- Ã‰tape 7 : Enrichissement Unpaywall ---
        with st.spinner(f"Enrichissement Unpaywall pour {collection_a_chercher_rennes}..."):
            progress_text_area_rennes.info("Ã‰tape 7/9 : Enrichissement Unpaywall...")
            progress_bar_rennes.progress(70)
            result_df_rennes = enrich_w_upw_parallel(result_df_rennes.copy())
            st.success(f"Enrichissement Unpaywall pour {collection_a_chercher_rennes} terminÃ©.")

        # --- Ã‰tape 8 : Permissions de dÃ©pÃ´t ---
        with st.spinner(f"RÃ©cupÃ©ration des permissions pour {collection_a_chercher_rennes}..."):
            progress_text_area_rennes.info("Ã‰tape 8/9 : RÃ©cupÃ©ration des permissions de dÃ©pÃ´t...")
            progress_bar_rennes.progress(80)
            result_df_rennes = add_permissions_parallel(result_df_rennes.copy())
            st.success(f"Permissions pour {collection_a_chercher_rennes} rÃ©cupÃ©rÃ©es.")

        # --- Ã‰tape 9 : DÃ©duction des actions et auteurs ---
        progress_text_area_rennes.info("Ã‰tape 9/9 : DÃ©duction des actions et traitement des auteurs...")
        if 'Action' not in result_df_rennes.columns: result_df_rennes['Action'] = pd.NA
        result_df_rennes['Action'] = result_df_rennes.apply(deduce_todo, axis=1)

        if fetch_authors_rennes: 
            with st.spinner(f"RÃ©cupÃ©ration des auteurs Crossref pour {collection_a_chercher_rennes}..."):
                if 'doi' in result_df_rennes.columns:
                    from concurrent.futures import ThreadPoolExecutor 
                    from tqdm import tqdm 

                    dois_for_authors_rennes = result_df_rennes['doi'].fillna("").tolist()
                    authors_results_rennes = []
                    with ThreadPoolExecutor(max_workers=10) as executor:
                        authors_results_rennes = list(tqdm(executor.map(get_authors_from_crossref, dois_for_authors_rennes), total=len(dois_for_authors_rennes), desc="Auteurs Crossref (rennes)"))
                    
                    result_df_rennes['Auteurs_Crossref'] = ['; '.join(author_l) if isinstance(author_l, list) and not any("Erreur" in str(a) or "Timeout" in str(a) for a in author_l) else (author_l[0] if isinstance(author_l, list) and author_l else '') for author_l in authors_results_rennes]
                    st.success(f"Auteurs Crossref pour {collection_a_chercher_rennes} rÃ©cupÃ©rÃ©s.")
                else:
                    st.warning("Colonne 'doi' non trouvÃ©e, impossible de rÃ©cupÃ©rer les auteurs pour la version rennes.")
                    result_df_rennes['Auteurs_Crossref'] = ''
            
            if compare_authors_rennes and uploaded_authors_file_rennes:
                with st.spinner(f"Comparaison des auteurs (fichier) pour {collection_a_chercher_rennes}..."):
                    try:
                        user_authors_df_rennes_file = pd.read_csv(uploaded_authors_file_rennes)
                        if not ({'collection', user_authors_df_rennes_file.columns[1]} <= set(user_authors_df_rennes_file.columns)):
                            st.error("Fichier CSV auteurs mal formatÃ© pour la version rennes.")
                        else:
                            author_name_col_rennes_file = user_authors_df_rennes_file.columns[1]
                            noms_ref_rennes_list = user_authors_df_rennes_file[user_authors_df_rennes_file["collection"].astype(str).str.lower() == str(collection_a_chercher_rennes).lower()][author_name_col_rennes_file].dropna().unique().tolist()
                            if not noms_ref_rennes_list:
                                st.warning(f"Aucun chercheur pour '{collection_a_chercher_rennes}' dans le fichier fourni (rennes).")
                            else:
                                chercheur_map_rennes_file = {normalize_name(n): n for n in noms_ref_rennes_list}
                                initial_map_rennes_file = {get_initial_form(normalize_name(n)): n for n in noms_ref_rennes_list}
                                from difflib import get_close_matches 

                                def detect_known_authors_rennes_file(authors_str_rennes):
                                    if pd.isna(authors_str_rennes) or not str(authors_str_rennes).strip() or "Erreur" in authors_str_rennes or "Timeout" in authors_str_rennes: return ""
                                    authors_pub_rennes = [a.strip() for a in str(authors_str_rennes).split(';') if a.strip()]
                                    detectes_originaux_rennes = set()
                                    for author_o_rennes in authors_pub_rennes:
                                        author_n_rennes = normalize_name(author_o_rennes)
                                        author_i_n_rennes = get_initial_form(author_n_rennes)
                                        match_c_rennes = get_close_matches(author_n_rennes, chercheur_map_rennes_file.keys(), n=1, cutoff=0.85)
                                        if match_c_rennes:
                                            detectes_originaux_rennes.add(chercheur_map_rennes_file[match_c_rennes[0]])
                                            continue
                                        match_i_rennes = get_close_matches(author_i_n_rennes, initial_map_rennes_file.keys(), n=1, cutoff=0.9)
                                        if match_i_rennes:
                                            detectes_originaux_rennes.add(initial_map_rennes_file[match_i_rennes[0]])
                                    return "; ".join(sorted(list(detectes_originaux_rennes))) if detectes_originaux_rennes else ""
                                result_df_rennes['Auteurs_Laboratoire_DÃ©tectÃ©s'] = result_df_rennes['Auteurs_Crossref'].apply(detect_known_authors_rennes_file)
                                st.success(f"Comparaison auteurs (fichier) pour {collection_a_chercher_rennes} terminÃ©e.")
                    except Exception as e_auth_file_rennes_exc:
                        st.error(f"Erreur fichier auteurs (rennes): {e_auth_file_rennes_exc}")
            elif compare_authors_rennes and not uploaded_authors_file_rennes:
                 st.warning("Veuillez tÃ©lÃ©verser un fichier CSV de chercheurs pour la comparaison des auteurs (rennes).")

        progress_bar_rennes.progress(90)
        st.success(f"DÃ©duction des actions et traitement des auteurs pour {collection_a_chercher_rennes} terminÃ©s.")
        
        st.dataframe(result_df_rennes)

        # --- Fusionner les auteurs/institutions dans le DataFrame final ---        
        if 'doi' in result_df_rennes.columns:
            def normalize_doi(doi):
                if not doi:
                    return ""
                return (
                    str(doi)
                    .lower()
                    .strip()
                    .replace("https://doi.org/", "")
                    .replace("http://doi.org/", "")
                    .replace("doi:", "")
                )

            # ðŸ§  RÃ©cupÃ¨re les publications OpenAlex dÃ©jÃ  stockÃ©es
            openalex_data = st.session_state.get('openalex_publications_raw', [])
            oa_map = {normalize_doi(p.get('doi')): p for p in openalex_data if p.get('doi')}

            merged_records = []
            enriched_count = 0
            for rec in result_df_rennes.to_dict(orient='records'):
                doi = normalize_doi(rec.get('doi'))
                if doi in oa_map:
                    oa_entry = oa_map[doi]
                    rec['authors'] = oa_entry.get('authors', [])
                    rec['institutions'] = oa_entry.get('institutions', [])
                    enriched_count += 1
                else:
                    rec['authors'] = []
                    rec['institutions'] = []
                merged_records.append(rec)

            # âœ… Met Ã  jour le DataFrame fusionnÃ©
            result_df_rennes = pd.DataFrame(merged_records)
            st.success(f"âœ… Fusion OpenAlex effectuÃ©e : {enriched_count} notices enrichies sur {len(result_df_rennes)}.")
        else:
            st.warning("âš ï¸ Aucun DOI trouvÃ© dans result_df_rennes : fusion impossible.")

        
        # --- Sauvegarde persistante des rÃ©sultats pour permettre les actions aprÃ¨s rerun ---
        try:
            st.session_state['last_result_df'] = result_df_rennes.to_dict(orient='records')
            st.session_state['last_collection'] = collection_a_chercher_rennes
            st.success("âœ… RÃ©sultats sauvegardÃ©s en session â€” vous pouvez gÃ©nÃ©rer le ZIP sans relancer la recherche.")
        except Exception as e:
            st.warning(f"Impossible de sauvegarder les rÃ©sultats en session: {e}")

        # --- Export XML HAL (prÃ©paration) ---
        st.write("AperÃ§u (head) des rÃ©sultats :", result_df_rennes.head())
        st.write(f"Total lignes result_df_rennes : {len(result_df_rennes)}")

        st.write("ðŸ” Exemple aprÃ¨s fusion (1Ã¨re ligne enrichie) :")
        if not result_df_rennes.empty:
            first_row = result_df_rennes.iloc[0].to_dict()
            st.json(first_row)


        # --- Export CSV classique ---
        if not result_df_rennes.empty:
            csv_export_rennes_data = result_df_rennes.to_csv(index=False, encoding='utf-8-sig')
            output_filename_rennes_final = f"c2LabHAL_resultats_{collection_a_chercher_rennes.replace(' ', '_')}_{start_year_rennes}-{end_year_rennes}.csv"
            st.download_button(
                label=f"ðŸ“¥ TÃ©lÃ©charger les rÃ©sultats pour {collection_a_chercher_rennes}",
                data=csv_export_rennes_data,
                file_name=output_filename_rennes_final,
                mime="text/csv",
                key=f"download_rennes_{collection_a_chercher_rennes}"
            )


        # -----------------------
        # Panneau minimal : un seul bouton visible "TÃ©lÃ©charger le ZIP"
        # -----------------------
        # DÃ©faut sÃ»r si rien n'est dÃ©fini (Ã©vite erreurs aprÃ¨s rerun)
        pubs_to_export = []
        if st.session_state.get('last_result_df') is not None:
            last_df = pd.DataFrame(st.session_state['last_result_df'])
            last_collection = st.session_state.get('last_collection', 'unknown')

            st.markdown("---")
            st.subheader(f"ðŸ“¦ Export XML HAL â€” collection : {last_collection}")
            st.write(f"RÃ©sultats en session : {len(last_df)} lignes")

            # Filtrer publications hors HAL
            if 'Statut_HAL' in last_df.columns:
                mask_non_hal = last_df['Statut_HAL'].fillna("").astype(str).isin(
                    ["Hors HAL", "Dans HAL mais hors de la collection"]
                )
                pubs_to_export = last_df[mask_non_hal].to_dict(orient="records")
            else:
                pubs_to_export = last_df.to_dict(orient='records')

            st.info(f"Publications candidates : {len(pubs_to_export)}")
            if pubs_to_export:
                st.write(pd.DataFrame(pubs_to_export[:3]))

            # Diagnostics avant le clic
            st.write("DEBUG â€” session_state keys:", list(st.session_state.keys()))
            if st.session_state.get('last_result_df'):
                st.write("DEBUG â€” taille last_result_df:", len(st.session_state['last_result_df']))
                # affiche le premier en JSON (sÃ»r mÃªme si pas d'authors)
                try:
                    st.write("DEBUG â€” first record keys:", list(st.session_state['last_result_df'][0].keys()))
                    st.json(st.session_state['last_result_df'][0])
                except Exception as e:
                    st.write("DEBUG â€” impossible d'afficher first record:", e)
            else:
                st.write("DEBUG â€” pas de last_result_df en session")

            # âœ… Bouton unique : gÃ©nÃ¨re directement le ZIP
            if st.button(f"â¬‡ï¸ TÃ©lÃ©charger le fichier ZIP des XML HAL ({len(pubs_to_export)})", key=f"dlzip_{last_collection}"):

                # DEBUG: Ã©tat au moment du clic (TRÃˆS important)
                st.write("CLICK â€” DEBUG session_state keys:", list(st.session_state.keys()))
                st.write("CLICK â€” pubs_to_export length:", len(pubs_to_export))
                if pubs_to_export:
                    try:
                        st.write("CLICK â€” premier pub (brief):", {
                            "Title": pubs_to_export[0].get("Title"),
                            "doi": pubs_to_export[0].get("doi"),
                            "authors_type": type(pubs_to_export[0].get("authors")),
                            "institutions_type": type(pubs_to_export[0].get("institutions")),
                        })
                        st.json(pubs_to_export[0])
                    except Exception as e:
                        st.write("CLICK â€” impossible d'afficher premier pub:", e)

                # Ensuite on gÃ©nÃ¨re (avec try/except)
                try:
                    with st.spinner("GÃ©nÃ©ration du ZIP en cours..."):
                        zipbuf = generate_zip_from_xmls(pubs_to_export)
                        # --- Diagnostic du retour ---
                        st.write("ðŸ” Type de retour generate_zip_from_xmls:", type(zipbuf))
                        if hasattr(zipbuf, "getvalue"):
                            st.write("â†’ getvalue() OK (BytesIO-like)")
                        elif isinstance(zipbuf, (bytes, bytearray)):
                            st.write("â†’ dÃ©jÃ  bytes")
                        else:
                            st.write("â†’ non-bytes et non-BytesIO (probablement ZipFile ou dict)")

                            
                except Exception as e:
                    import traceback
                    st.error(f"Erreur pendant la gÃ©nÃ©ration du ZIP : {e}")
                    st.text(traceback.format_exc())


                # Bouton de tÃ©lÃ©chargement
                if st.session_state.get('zip_buffer'):
                    st.download_button(
                        label="â¬‡ï¸ TÃ©lÃ©charger le fichier ZIP des XML HAL (cliquer ici)",
                        data=st.session_state['zip_buffer'],
                        file_name=f"hal_exports_{last_collection}.zip",
                        mime="application/zip",
                        key=f"download_zip_{last_collection}"
                    )

            # â¬‡ï¸ Ce bloc est Ã  placer juste APRÃˆS le if st.button(...)
            #    (mÃªme indentation, donc un cran Ã  gauche)
            st.write("POST-CLICK â€” zip_buffer present:", 'zip_buffer' in st.session_state)
            if 'zip_buffer' in st.session_state:
                st.write(
                    "POST-CLICK â€” taille zip_buffer (bytes len):",
                    len(st.session_state['zip_buffer'])
                    if isinstance(st.session_state['zip_buffer'], (bytes, bytearray))
                    else "non-bytes"
                )

        # âš ï¸ Ce else doit Ãªtre au mÃªme niveau dâ€™indentation que le bloc "if st.session_state..."
        else:
            st.info("âš ï¸ Aucune recherche en session. Lancez d'abord la recherche.")

        # âœ… Toujours Ã  la toute fin du script (hors condition)
        progress_bar_rennes.progress(100)
        progress_text_area_rennes.success(
            f"ðŸŽ‰ Traitement pour {collection_a_chercher_rennes} terminÃ© avec succÃ¨s !"
        )

# -----------------------
# Fonctions utilitaires pour assainir les auteurs/institutions
# -----------------------

def _ensure_authors_struct(auth_field):
    """
    Transforme n'importe quelle forme de 'authors' en liste normalisÃ©e :
    [{'name':..., 'orcid':..., 'raw_affiliations':[...]}]
    """
    import json

    # Cas vide
    if not auth_field:
        return []

    # Si c'est dÃ©jÃ  une liste de dicts
    if isinstance(auth_field, list):
        clean_list = []
        for a in auth_field:
            if isinstance(a, dict):
                clean_list.append({
                    "name": _safe_text(a.get("name", "")),
                    "orcid": _safe_text(a.get("orcid", "")),
                    "raw_affiliations": _ensure_list(a.get("raw_affiliations"))
                })
            elif isinstance(a, str):
                # cas Ã©trange : liste de strings
                clean_list.append({"name": _safe_text(a), "orcid": "", "raw_affiliations": []})
        return clean_list

    # Si c'est une chaÃ®ne JSON ou une string quelconque
    if isinstance(auth_field, str):
        try:
            parsed = json.loads(auth_field)
            return _ensure_authors_struct(parsed)
        except Exception:
            # plain string (ex: "John Doe, Jane Smith")
            parts = [p.strip() for p in auth_field.split(",") if p.strip()]
            return [{"name": p, "orcid": "", "raw_affiliations": []} for p in parts]

    # Sinon : cas inattendu (dict unique, None, etc.)
    if isinstance(auth_field, dict):
        return [_ensure_authors_struct(auth_field)]
    return []

def _ensure_institutions_struct(inst_field):
    """
    Retourne une liste de dicts d'institutions {'display_name','ror','type','country'}.
    GÃ¨re list/dict/str.
    """
    if inst_field is None:
        return []
    if isinstance(inst_field, list):
        cleaned = []
        for it in inst_field:
            if isinstance(it, dict):
                cleaned.append({
                    "display_name": _safe_text(it.get("display_name", "")).strip(),
                    "ror": _safe_text(it.get("ror", "")).strip(),
                    "type": it.get("type", "institution"),
                    "country": it.get("country", "")
                })
            elif isinstance(it, str):
                cleaned.append({"display_name": it.strip(), "ror": "", "type": "institution", "country": ""})
        return cleaned
    if isinstance(inst_field, dict):
        return [_ensure_institutions_struct([inst_field])[0]]
    # str
    s = str(inst_field).strip()
    if not s:
        return []
    # si c'est 'display_name|ror' ou 'ror|display_name' possible split
    if '|' in s:
        parts = [p.strip() for p in s.split('|')]
        return [{"display_name": parts[0], "ror": parts[1] if len(parts)>1 else "", "type": "institution", "country": ""}]
    return [{"display_name": s, "ror": "", "type": "institution", "country": ""}]

if __name__ == "__main__":
    main()
